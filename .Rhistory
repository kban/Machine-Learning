seq(1, 20)
seq(0, 10, by=0.5)
seq(5, 10, length=30)
my_seq <- seq(5, 10, length=30)
length(my_seq)
1:length(my_seq)
seq(along.with = my_seq)
seq_along(my_seq)
rep(0, times = 40)
rep(c(0, 1, 2), times = 10)
rep(c(0, 1, 2), each = 10)
num_vect<-vector(0.5, 55, -10, 6)
num_vect
num_vect<-vector(0.5, 55)
?vector
num_vect<-as.vector(c(0.5, 55, -10, 6), mode = "numeric"))
num_vect<-as.vector(c(0.5, 55, -10, 6), mode = "numeric")
?c
c(0.5, 55, -10, 6)
num_vect<-c(0.5, 55, -10, 6)
tf<- num_vect < 1
tf
num_vect >= 6
my_char<-c("My", "name", "is")
my_char
paste(my_char, collapse = " ")
my_name<-c(my_char, "Ivan")
my_name
paste(my_name, collapse = " ")
paste("Hello", "world!", sep = " ")
paste(c("X", "Y", "Z"), sep = " ")
paste(1:3, c("X", "Y", "Z"), sep = "")
paste(LETTERS, 1:4, sep = "-")
x<-c(44, NA, 5, NA)
x + 3
x *3
y <- rnorm(1000)
z <- rep(NA, 1000)
my_data <- sample(c(y, z), 100)
my_na<-is.na(my_data)
my_na
my_data == NA
sum(my_na)
my_data
0/0
Inf/Inf
Inf - Inf
x
x[1:10]
x[is.na(x)]
y <- x[!is.na(x)]
y
y[y > 0]
x[x > 0]
x[!is.na(x) & x
| > 0]
x[!is.na(x) & x | > 0]
x[!is.na(x) & x | x > 0]
x[!is.na(x) & x > 0]
x[c(3,5,7)]
x[0]
x[300]
x[3000]
x[c(-2, -10)]
x[-c(2, 10)]
vect <- c(foo = 11, bar = 2, norf = NA)
vect
names(vect)
vect2<-c(11, 2, NA)
names(vect2) <- c("foo", "bar", "norf")
identical(vect2)
identical(vect,vect2)
vect["bar"]
vect[c("foo", "bar")]
my_vector<-c(1:20)
?c
my_vector<-1:20
my_vector
dim(my_vector)
length(my_vector)
dim(my_vector) <- c(4, 5)
dim(my_vector)
attributes(my_vector)
my_vector
class(my_vector)
my_matrix<-my_vector
?matrix
my_matrix2<-matrix(1:20,nrow=4,ncol=5)
identical(my_matrix,my_matrix2)
patients<-c("Bill", "Gina", "Kelly", "Sean")
cbind(patients,my_matrix)
my_data <- data.frame(patients, my_matrix)
my_data
class("frame")
class("my_data")
class(my_data)
c("patient", "age", "weight", "bp", "rating", "test")
cnames<-c("patient", "age", "weight", "bp", "rating", "test")
colnames(my_data)
olnames(my_data) <- cnames
colnames(my_data) <- cnames
my_data
source("D:/work/R/noNa.R")
f<-file("D:/work/R/hw1_data.csv","r")
data<-read.csv(f,header=TRUE,fill = FALSE)
data
data[1:2]
data[,1:2]
data
data(2)
nonN<-comleteFunc(data,"Ozone")
nonN
mean(nonN$Ozone)
ot<-filterByOzoneAndTemp(data,31,90)
ot
mean(ot$Solar.R)
m1<-filterByMonth(data,6)
m1
mean(m1$Temp)
m1
m2<-filterByMonth(data,5)
m2
max(m2$Ozone)
nonN
m2
res<-comleteFunc(m2,"Ozon")
res<-comleteFunc(m2,"Ozone")
res
max(res$Ozone)
swirl()
?swirl
install.packages("swirl")
swirl()
library(swirl)
swirl()
TRUE == TRUE
(FALSE == TRUE) == FALSE
6==7
6<7
10<=10
5!=7
5!=7
!(5==7)
FALSE & FALSE
TRUE & c(TRUE, FALSE, FALSE)
TRUE && c(TRUE, FALSE, FALSE)
TRUE | c(TRUE, FALSE, FALSE)
TRUE || c(TRUE, FALSE, FALSE)
5 > 8 || 6 != 8 && 4 > 3.9
isTRUE(6 > 4)
identical('twins', 'twins')
xor(5 == 6, !FALSE)
ints <- sample(10)
ints
ints > 5
which(ints>7)
any(ints<0)
all(inits>0)
all(ints>0)
library("swirl")
swirl()
Sys.Date()
mean(c(2, 4, 5))
script
ls
ls()
character
set.seed(1)
rpois(5, 2)
set.seed(1)
rpois(5, 2)
set.seed(1)
rpois(5, 2)
set.seed(10)
x <- rep(0:1, each = 5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
load(swirl)
library(swirl)
swirl()
ls()
class(plants)
dim(plants)
nrow(plants)
ncol(plants)
object.size(plants)
names(plants)
head()
head(12)
head(plants)
head(plants,10)
tail(plants,15)
summary(plants)
table(plants$Active_Growth_Period)
str(plants)
?sample
sample(1:6, 4, replace = TRUE)
sample(1:6, 4, replace = TRUE)
sample(1:20, 10)
LETTERS
sample(LETTERS)
flips = sample(0:1, 100, replacement = TRUE)
flips = sample(0:1, 100, replace = TRUE)
flips <- sample(c(0,1), 100, replace = TRUE, prob = c(0.3, 0.7))
flips
sum()flips
sum(flips)
?rbinom
rbinom(1, size = 100, prob = 0.7)
flips2 <- rbinom(100, size = 1, prob = 0.7)
flips2
sum(flips2)
?rnorm
rnorm(10)
rnorm(10, mean = 100, sd=25)
?rpois
rnorm(5, mean = 10, sd=25)
rpois(5, 10)
replicate(100, rpois(5, 10))
my_pois <- replicate(100, rpois(5, 10))
my_pois
cm <- colMeans(my_pois)
hist(cm)
?sample
sample(1:6, 4, replace = TRUE)
sample(1:6, 4, replace = TRUE)
q
qiuit()
quit()
library(swirl)
swirl()
q
exit
q
w
cancel
a
q
we
fuck you mother fucker!
ss
q
q()
install_from_swirl("Getting and Cleaning Data")
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf -> read.csv(path2csv,stringsAsFactors = FALSE)
mydf <- read.csv(path2csv,stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran(tbl_df)
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
quit()
library(hdf5)
library(rhdf5)
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library(rhdf5)
library(httr)
load(sqirl)
library(swirl)
swirl()
exit
qd
quit()
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(lattice)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
install.packages('ggplot2')
qplot(Wind, Ozone, data = airquality, geom = "smooth")
library(qplot)
library('qplot')
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
library(ggplot2)
library(qplot)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
qplot(Wind, Ozone, data = airquality)
library(ggplot2)
library(ggplot2movies)
g <- ggplot(movies, aes(votes, rating))
print(g)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
load('AppliedPredictiveModeling')
install.packages(AppliedPredictiveModeling)
install.packages('AppliedPredictiveModeling')
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
predictors
diagnosis
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData
adData = data.frame(diagnosis,predictors)
adData
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
install.packages('caret')
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
require(Hmisc)
inds<-1:nrow(training)
# view step pattern in plot
q<-qplot(x = inds, y = CompressiveStrength, data = training); q
# apply a cut to all the columns of the training data
nameslist<-names(training)
cutall<-sapply(nameslist, function(nameslist){
cut2(training[[nameslist]], g=5)
})
cutall<-as.data.frame(cutall)
cutnames<-sapply(nameslist, function(nameslist){paste("cut", nameslist, sep="")})
colnames(cutall)<-cutnames
# plot the data coloured by the cuts in each of the variables
for(Var in names(cutall)) {
print(qplot(x = inds, y = CompressiveStrength, data=training, color=cutall[[Var]], main = Var))
}
q
library(Hmisc)
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(Cement,g=4))
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(BlastFurnaceSlag,g=4))
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(FlyAsh,g=3))
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(Water,g=4))
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(Superplasticizer,g=4))
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(CoarseAggregate,g=4))
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(FineAggregate,g=4))
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(Age,g=4))
install.packages('Hmisc ')
install.packages('Hmisc')
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(Hmisc)
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(Cement,g=4))
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(BlastFurnaceSlag,g=4))
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(FlyAsh,g=3))
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(Water,g=4))
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(Superplasticizer,g=4))
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(CoarseAggregate,g=4))
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(FineAggregate,g=4))
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(Age,g=4))
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(Cement,g=4))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
subset = training[,grep("^IL", names(training))]
preProcess(subset, thresh = 0.8, method = "pca")$numComp
inds<-grep(pattern = "^IL", x = names(training))
names(training)[inds]
preProc<-preProcess(x = training[, inds], method="pca", thresh = 0.8)
preProc
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
testing = adData[-inTrain,]
> library(caret)
> library(AppliedPredictiveModeling)
> set.seed(3433)
> data(AlzheimerDisease)
> adData = data.frame(diagnosis,predictors)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[inTrain,]
testing = adData[-inTrain,]
inds<-grep(pattern = "^IL", x = names(training))
names(training)[inds]
preProc<-preProcess(x = training[, inds], method="pca", thresh = 0.8)
preProc
subset = training[,grep("^IL", names(training))]
preProcess(subset, thresh = 0.8, method = "pca")$numComp
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainSubset = training[,grep("^IL", names(training))]
testSubset = testing[,grep("^IL", names(testing))]
pp = preProcess(trainSubset, thresh = 0.8, method = "pca")
trainTransformed <- predict(pp, trainSubset)
testTransformed <- predict(pp, testSubset)
trainSubset$diagnosis = training$diagnosis
testSubset$diagnosis = testing$diagnosis
trainTransformed$diagnosis = training$diagnosis
testTransformed$diagnosis = testing$diagnosis
glmpca = train(diagnosis ~ ., data = trainTransformed, method = "glm")
glm = train(diagnosis ~ ., data = trainSubset, method = "glm")
round(confusionMatrix(testSubset$diagnosis,predict(glm, testSubset))$overall["Accuracy"],2)
round(confusionMatrix(testTransformed$diagnosis,predict(glmpca, testTransformed))$overall["Accuracy"],2)
install.packages('e1071')
trainSubset = training[,grep("^IL", names(training))]
testSubset = testing[,grep("^IL", names(testing))]
pp = preProcess(trainSubset, thresh = 0.8, method = "pca")
trainTransformed <- predict(pp, trainSubset)
testTransformed <- predict(pp, testSubset)
trainSubset$diagnosis = training$diagnosis
testSubset$diagnosis = testing$diagnosis
trainTransformed$diagnosis = training$diagnosis
testTransformed$diagnosis = testing$diagnosis
glmpca = train(diagnosis ~ ., data = trainTransformed, method = "glm")
glm = train(diagnosis ~ ., data = trainSubset, method = "glm")
round(confusionMatrix(testSubset$diagnosis,predict(glm, testSubset))$overall["Accuracy"],2)
round(confusionMatrix(testTransformed$diagnosis,predict(glmpca, testTransformed))$overall["Accuracy"],2)
# obtain all variable names beginning with IL
inds<-grep(pattern = "^IL", x = names(training))
# obtain the index of the variable diagnosis
digInd<-grep(pattern = "diagnosis", x = names(training))
# concatenate
allInds<-c(digInd, inds)
# define new training and test sets
training2<-training[,allInds]; testing2<-testing[,allInds]
# build a prediction model using all the predictors
modelFit<-train(diagnosis ~., data = training2, method = "glm")
predictions<-predict(object = modelFit, newdata = testing2)
confusionMatrix(data = predictions, testing2$diagnosis)
# preprocess the new training set to obtain the PCs that explain 80% of the variation
preProc<-preProcess(x = training2[, -1], method = "pca", thresh = 0.8)
trainPC<-predict(preProc, newdata = training2[, -1])
pc_modelFit<-train(training2$diagnosis ~.,method = "glm", data = trainPC)
testPC<-predict(preProc, newdata = testing2[, -1])
confusionMatrix(testing2$diagnosis, predict(pc_modelFit, testPC))
trainSubset = training[,grep("^IL", names(training))]
testSubset = testing[,grep("^IL", names(testing))]
pp = preProcess(trainSubset, thresh = 0.8, method = "pca")
trainTransformed <- predict(pp, trainSubset)
testTransformed <- predict(pp, testSubset)
trainSubset$diagnosis = training$diagnosis
testSubset$diagnosis = testing$diagnosis
trainTransformed$diagnosis = training$diagnosis
testTransformed$diagnosis = testing$diagnosis
glmpca = train(diagnosis ~ ., data = trainTransformed, method = "glm")
glm = train(diagnosis ~ ., data = trainSubset, method = "glm")
round(confusionMatrix(testSubset$diagnosis,predict(glm, testSubset))$overall["Accuracy"],2)
round(confusionMatrix(testTransformed$diagnosis,predict(glmpca, testTransformed))$overall["Accuracy"],2)
library(lattice); library(ggplot2); library(caret); library(randomForest); library(rpart); library(rpart.plot);
install.packages('rpart')
install.packages("rpart")
library(lattice); library(ggplot2); library(caret); library(randomForest); library(rpart); library(rpart.plot);
install.packages("rpart.plot")
library(lattice); library(ggplot2); library(caret); library(randomForest); library(rpart); library(rpart.plot);
install.packages('RCurl')
getwd()
setwd('d:\work/R/Machine learning/')
setwd('d:/work/R/Machine learning/')
load('machineLearningCourseProject.R')
source('machineLearningCourseProject.R')
source('machineLearningCourseProject.R')
source('machineLearningCourseProject.R')
source('machineLearningCourseProject.R')
source('machineLearningCourseProject.R')
source('machineLearningCourseProject.R')
clear()
clear
source('machineLearningCourseProject.R')
source('machineLearningCourseProject.R')
